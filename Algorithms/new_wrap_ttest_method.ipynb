{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import operator\n",
    "import collections\n",
    "import statsmodels.stats.multitest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Param df:\n",
    "    A dataframe containing the label column, and one or more real valued comparison columns.\n",
    "    \n",
    "@Param label_column:\n",
    "    The name of the label column. This column must be in the dataframe, and must contain exactly 2 unique values.\n",
    "    \n",
    "@Param comparison_columns (default - will use all in dataframe):\n",
    "    A list of columns on which t-tests will be performed. Each column must be in the dataframe, and must be real valued.\n",
    "    If no value is specified, by default it will use every column in the dataframe, aside from the specified label column.\n",
    "\n",
    "@Param alpha (default = .05):\n",
    "    Significance level. Will be adjusted using parameter correction_method if more than 1 comparison is done.\n",
    "    \n",
    "@Param return_all (default = False):\n",
    "    Boolean. If true, will return a dataframe containing all comparisons and p-values, regardless of significance.\n",
    "    If false, will only return significant comparisons and p-values in the dataframe, or None if no significant comparisons.\n",
    "\n",
    "@Param correction_method (default = 'bonferroni')\n",
    "    String. Specifies method of adjustment for multiple testing. See -\n",
    "    https://www.statsmodels.org/stable/generated/statsmodels.stats.multitest.multipletests.html\n",
    "    - for documentation and available methods.\n",
    "    \n",
    "@Return:\n",
    "    A pandas dataframe of column names and corresponding p-values which were determined to be significant in \n",
    "    the comparison, sorted by significance (smallest p-values at the head). The 2 columns of the dataframe are \n",
    "    'Comparison' and 'P_Value'.\n",
    "    Returns None if dataframe was not formatted properly, or if no comparison was significant.\n",
    "    \n",
    "This method takes as a parameter a dataframe. Must be formatted in the following way. 1 column declared as the label column, with \n",
    "the name of this column passed in as the second parameter. The Label column must contain exactly 2 unique entries,\n",
    "and every row in the dataframe must have one of these 2 values in this column. The remaining columns will be real \n",
    "valued columns on which t-tests will be done. A list of real valued columns on which to do t-tests will be passed in \n",
    "as the third parameter. No t-test will be done on columns not included in this list.\n",
    "\n",
    "The wrap_ttest method will then compare the two groups, as partitioned by the two values in the Label column, and \n",
    "perform t-tests for each real valued column in the passed in list, generating a p-value.\n",
    "The resulting p-values will be corrected for multiple testing, using a specified 'correction_method', and a dataframe with \n",
    "the significant results will be returned as a dataframe, sorted by p-value.\n",
    "'''\n",
    "\n",
    "def wrap_ttest(df, label_column, comparison_columns=None, alpha=.05, return_all=False, correction_method='bonferroni'):\n",
    "    try:\n",
    "        '''Verify precondition that label column exists and has exactly 2 unique values'''\n",
    "        label_values = df[label_column].unique()\n",
    "        if len(label_values) != 2:\n",
    "            print(\"Incorrectly Formatted Dataframe! Label column must have exactly 2 unique values.\")\n",
    "            return None\n",
    "\n",
    "        '''Partition dataframe into two sets, one for each of the two unique values from the label column'''\n",
    "        partition1 = df.loc[df[label_column] == label_values[0]]\n",
    "        partition2 = df.loc[df[label_column] == label_values[1]]\n",
    "\n",
    "        '''If no comparison columns specified, use all columns except the specified labed column'''\n",
    "        if not comparison_columns:\n",
    "            comparison_columns = list(df.columns)\n",
    "            comparison_columns.remove(label_column)\n",
    "\n",
    "        '''Determine the number of real valued columns on which we will do t-tests'''\n",
    "        number_of_comparisons = len(comparison_columns)\n",
    "\n",
    "        '''Store comparisons and p-values in two arrays'''\n",
    "        comparisons = []\n",
    "        pvals = []\n",
    "\n",
    "        '''Loop through each comparison column, perform the t-test, and record the p-val'''\n",
    "        for column in comparison_columns:\n",
    "            stat, pval = scipy.stats.ttest_ind(partition1[column].dropna(axis=0), partition2[column].dropna(axis=0))\n",
    "            comparisons.append(column)\n",
    "            pvals.append(pval)\n",
    "            \n",
    "        '''Correct for multiple testing to determine if each comparison meets the new cutoff'''\n",
    "        results = statsmodels.stats.multitest.multipletests(pvals=pvals, alpha=alpha, method=correction_method)\n",
    "        reject = results[0]\n",
    "        \n",
    "        '''Format results in a pandas dataframe'''\n",
    "        results_df = pd.DataFrame(columns=['Comparison','P_Value'])\n",
    "\n",
    "        '''If return all, add all comparisons and p-values to dataframe'''\n",
    "        if return_all:\n",
    "            results_df['Comparison'] = comparisons\n",
    "            results_df['P_Value'] = pvals\n",
    "        \n",
    "            '''Else only add significant comparisons'''\n",
    "        else:\n",
    "            for i in range(0, len(reject)):\n",
    "                if reject[i]:\n",
    "                    results_df = results_df.append({'Comparison':comparisons[i],'P_Value':pvals[i]}, ignore_index=True)\n",
    "                    \n",
    "              \n",
    "        '''Sort dataframe by ascending p-value'''\n",
    "        results_df = results_df.sort_values(by='P_Value', ascending=True)\n",
    "        results_df = results_df.reset_index(drop=True)\n",
    "        \n",
    "        '''If results df is not empty, return it, else return None'''\n",
    "        if len(results_df) > 0:\n",
    "            return results_df\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        print(\"Incorrectly Formatted Dataframe!\")\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
